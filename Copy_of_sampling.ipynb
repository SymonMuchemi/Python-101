{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hZUxWhia0h1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python code cell is importing several libraries and modules necessary for data analysis and machine learning tasks:\n",
        "\n",
        "1. `numpy` (as `np`): This is a fundamental package for scientific computing with Python. It provides support for arrays, matrices and many mathematical functions to operate on these data structures.\n",
        "\n",
        "2. `pandas` (as `pd`): This library provides high-performance, easy-to-use data structures and data analysis tools for Python.\n",
        "\n",
        "3. `matplotlib.pyplot` (as `plt`): This is a plotting library for creating static, animated, and interactive visualizations in Python.\n",
        "\n",
        "4. `seaborn` (as `sns`): This is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
        "\n",
        "5. `sklearn.datasets.load_iris`: This function loads the Iris Plants Database for machine learning.\n",
        "\n",
        "6. `sklearn.model_selection.train_test_split`: This function splits arrays or matrices into random train and test subsets.\n",
        "\n",
        "7. `sklearn.neighbors.KNeighborsClassifier`: This is the object for the k-nearest neighbors (KNN) algorithm for classification from the scikit-learn library.\n",
        "\n",
        "8. `sklearn.metrics.accuracy_score`, `sklearn.metrics.f1_score`: These functions compute the accuracy and F1 score, which are metrics for evaluating classification models.\n",
        "\n",
        "9. `imblearn.over_sampling.RandomOverSampler`: This is a method for random over-sampling, which is a technique used to handle imbalanced datasets.\n",
        "\n",
        "10. `imblearn.under_sampling.RandomUnderSampler`: This is a method for random under-sampling, which is another technique used to handle imbalanced datasets.\n",
        "\n",
        "11. `imblearn.over_sampling.SMOTE`: This stands for Synthetic Minority Over-sampling Technique. It is a type of data augmentation for minority classes and is used to handle imbalanced datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjZ0Hxlra9PI"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['Species'] = data.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python code cell is responsible for loading the Iris dataset and converting it into a pandas DataFrame:\n",
        "\n",
        "1. `data = load_iris()`: This line loads the Iris dataset, which is a simple, prepackaged dataset provided by scikit-learn. The Iris dataset is a classic dataset for classification, machine learning, and data visualization.\n",
        "\n",
        "2. `df = pd.DataFrame(data.data, columns=data.feature_names)`: This line creates a pandas DataFrame from the Iris dataset. The `data.data` attribute contains the features (sepal length, sepal width, petal length, and petal width), and `data.feature_names` provides the column names for these features.\n",
        "\n",
        "3. `df['Species'] = data.target`: This line adds a new column to the DataFrame, 'Species', which represents the class of each instance (setosa, versicolor, or virginica). The `data.target` attribute contains these class labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c60cOzHldBvi"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "X = df.drop('Species', axis=1)\n",
        "y = df['Species']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python code cell is responsible for preparing the dataset for machine learning:\n",
        "\n",
        "1. `X = df.drop('Species', axis=1)`: This line creates a new DataFrame `X` which contains all the columns of the original DataFrame `df` except for 'Species'. This is done by using the `drop` function with `axis=1` (indicating that a column should be dropped), and 'Species' (the name of the column to drop). `X` will be used as the feature matrix for training the machine learning model.\n",
        "\n",
        "2. `y = df['Species']`: This line creates a new Series `y` which contains the 'Species' column of the DataFrame `df`. `y` will be used as the target vector for training the machine learning model.\n",
        "\n",
        "3. `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)`: This line splits the dataset into training and testing sets. The `train_test_split` function shuffles the dataset and then splits it. The `test_size=0.2` parameter means that 20% of the data will be used for the test set, and the rest for the training set. The `random_state=43` parameter ensures that the shuffle will be the same every time the code is run, which is important for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F8-1xOidFn6"
      },
      "outputs": [],
      "source": [
        "# Define a function to train and evaluate KNN with different sampling methods\n",
        "def train_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=5):\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python code cell defines a function, `train_evaluate_knn`, which trains a k-nearest neighbors (KNN) classifier on the provided training data and evaluates its performance on the test data. The performance is measured in terms of accuracy and weighted F1 score. The function returns these two metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWPjjxkYdFu5",
        "outputId": "22a1dea6-40ad-4350-fff3-ec73e2307cc3"
      },
      "outputs": [],
      "source": [
        "# Original\n",
        "accuracy, f1 = train_evaluate_knn(X_train, y_train, X_test, y_test)\n",
        "print(\"Original Data - Accuracy: {:.2f}% | F1 Score: {:.2f}\".format(accuracy * 100, f1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python code cell trains a k-nearest neighbors (KNN) classifier on the original, unmodified training data, and then evaluates its performance on the test data. The accuracy and F1 score of the model are calculated and printed in a formatted manner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpE4fhk2dRFa",
        "outputId": "6015342e-1292-46f4-ae0d-736df34f5ac2"
      },
      "outputs": [],
      "source": [
        "# Oversampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "accuracy, f1 = train_evaluate_knn(X_resampled, y_resampled, X_test, y_test)\n",
        "print(\"Oversampled Data - Accuracy: {:.2f}% | F1 Score: {:.2f}\".format(accuracy * 100, f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python code cell applies oversampling to the training data using the Random Over Sampler method to balance the classes. It then trains a k-nearest neighbors (KNN) classifier on the oversampled data and evaluates its performance on the test data. The accuracy and F1 score of the model are calculated and printed in a formatted manner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xV0ZdbidWV-",
        "outputId": "a760c989-d45a-4bd2-f61e-f74fa6026939"
      },
      "outputs": [],
      "source": [
        "# Undersampling\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
        "accuracy, f1 = train_evaluate_knn(X_resampled, y_resampled, X_test, y_test)\n",
        "print(\"Undersampled Data - Accuracy: {:.2f}% | F1 Score: {:.2f}\".format(accuracy * 100, f1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python code cell applies undersampling to the training data using the Random Under Sampler method to balance the classes. It then trains a k-nearest neighbors (KNN) classifier on the undersampled data and evaluates its performance on the test data. The accuracy and F1 score of the model are calculated and printed in a formatted manner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juXXNlW2dcNB",
        "outputId": "2ff79692-120e-4c23-c492-7639191c2ef8"
      },
      "outputs": [],
      "source": [
        "# SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "accuracy, f1 = train_evaluate_knn(X_resampled, y_resampled, X_test, y_test)\n",
        "print(\"SMOTE Data - Accuracy: {:.2f}% | F1 Score: {:.2f}\".format(accuracy * 100, f1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python code cell applies the Synthetic Minority Over-sampling Technique (SMOTE) to the training data to balance the classes. It then trains a k-nearest neighbors (KNN) classifier on the SMOTE data and evaluates its performance on the test data. The accuracy and F1 score of the model are calculated and printed in a formatted manner."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
